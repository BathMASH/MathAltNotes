\section*{Chapter 0: Recap from MA10207 and basic results}

\subsection{Sequences and series}

\begin{definition}
Let $(\alpha_k)_{k\in \N}$ be real sequence, namely $\alpha_k\in \R$ for every $k\in \N$. We say that $(\alpha_k)_{k\in \N}$ converges to a limit $L\in \R$, namely $L=\lim_{k\to \infty} \alpha_k$ if, by definition, for every $\varepsilon>0$ there exists $N\in \N$ such that 
$$
|\alpha_k  - L|< \varepsilon \quad \forall\, k\geq N.
$$
Equivalently, this means that 
\begin{equation}\label{e:ls}
L-\varepsilon< \alpha_k  < L+\varepsilon \quad \forall\, k\geq N.
\end{equation}
We say that $(\alpha_k)_{k\in \N}$ diverges to $+\infty$ (or that it diverges positively) if for every $M\in \R$ there exists $N\in \N$ such that 
$$
\alpha_k > M \quad \forall\, k\geq N.
$$
Similarly, we say that $(\alpha_k)_{k\in \N}$ diverges to $-\infty$ (or that it diverges negatively) if for every $M\in \R$ there exists $N\in \N$ such that 
$$
\alpha_k < M \quad \forall\, k\geq N.
$$
\bigskip
\begin{proposition}[Cauchy criterion for convergence]\label{cauchycritseq}
	The sequence $(\alpha_k)_{k\in \N}$ converges if and only if for each $\epsilon >0$, there exists $N$ such that
	$$
	|\alpha_k -\alpha_l| < \epsilon\ \ \forall k,l \geq N.
	$$
\end{proposition}


%Then we can see that while (1) in Proposition \ref{p:limsup} corresponds \underline{exactly} to the upper bound in \eqref{e:ls}, the condition (2) is instead weaker than the lower bound in \eqref{e:ls}.
\end{definition}

\bigskip
In computing limits of real sequences, it is helpful to remember some basic examples:
\bigskip
\begin{proposition} The following limits hold:
	\begin{itemize}
		\item Given $a\in \R$,
		$$
		\lim_{k\to +\infty} a^k = 
		\begin{cases}
		+ \infty \quad & \textrm{if } a>1,\\
		1 \quad & \textrm{if } a=1,\\
		0 \quad & \textrm{if } -1 < a < 1,
		\end{cases}
		$$
		and it does not exist for $a\leq -1$.
		\item For every $a>0$ we have 
		$$
		\lim_{k\to +\infty} a^{\frac1k} =1;
		$$
		\item For $b\in \R$ we have 
		$$
		\lim_{k\to +\infty} k^b = \begin{cases}
		+\infty \quad & \textrm{if } b>0,\\
		0 \quad & \textrm{if } b<0;
		\end{cases}
		$$
		\item For every $b\in \R$:
		$$
		\lim_{k\to +\infty} (k^b)^{\frac1k} =1;
		$$
		\item For every $b>0$ and $a>1$ we have 
		$$
		\lim_{k\to +\infty} \ln k = \lim_{k\to +\infty} k^b = \lim_{k\to +\infty} a^k = \lim_{k\to +\infty} k! = \lim_{k\to +\infty} k^k = +\infty;
		$$
		\item For every $b>0$ and $a>1$ we have 
		$$
		\lim_{k\to +\infty} \frac{\ln k}{k^b} = \lim_{k\to +\infty} \frac{k^b}{a^k} = \lim_{k\to +\infty} \frac{a^k}{k!} = \lim_{k\to +\infty} \frac{k!}{k^k} =0. 
		$$
	\end{itemize}

\bigskip
\begin{remark}
	Recall that, for a non-empty set $A\subset \R $, the infimum of $A$ is denoted by $\inf A$ and is the greatest lower bound for $A$. The infimum (which need not lie in $A$) is an element of $\overline{\R}=\R \cup\{+\infty, -\infty \}$  which is less than  or equal to any element in $A$ and arbitrarily close to elements of $A$.
	Similarly, $\sup A$ (which need not lie in $A$) is the least upper bound for $A$ and is an element of $\overline{\R}$  which is greater than or equal to any element in $A$ and arbitrarily close to elements of $A$.
\end{remark}

Although not every real sequence converges, we can always define the following notions of limit superior (limsup) and limit inferior (liminf) of a sequence:


\begin{definition}[Limit superior and limit inferior]
Let $(\alpha_k)_{k\in \N}$ be a real sequence. We define
\begin{align*}
\liminf_{k\to \infty} \alpha_k
& := \lim_{k\to \infty} \left(\inf\{\alpha_m: m\geq k\}\right) = \sup_{k\in \N} \left\{\inf\{\alpha_m: m\geq k\}\right\}
\end{align*}
 and
 \begin{align*}
\limsup_{k\to \infty} \alpha_k
&:= \lim_{k\to \infty} \left(\sup\{\alpha_m: m\geq k\}\right) = \inf_{k\in \N} \left\{\sup\{\alpha_m: m\geq k\}\right\}
%&=\sup\left(\lim_{m\to \infty} \alpha_{k_m}: (\alpha_{k_m})_m \,\, \text{converging subsequence} \right).
\end{align*}

Note that 
$$
\liminf_{k\to \infty} \alpha_k \leq \limsup_{k\to \infty} \alpha_k
$$
and that  $\liminf_{k\to \infty} \alpha_k = \limsup_{k\to \infty} \alpha_k = L$ if and only if $L=\lim_{k\to \infty} \alpha_k$.
\end{definition}

\bigskip
\begin{proposition}[Properties of $\limsup$ and $\liminf$]\label{p:limsup}
$ $

Let $(\alpha_k)_k$ be a real sequence; let $L_1= \liminf_{k\to \infty} \alpha_k$ and $L_2:= \limsup_{k\to \infty} \alpha_k$. Suppose further that $L_1,L_2\in \R$. Then
\begin{itemize}
\item[(1)] For every $\varepsilon>0$ there exists $N\in \N$ such that 
$$
\alpha_k  > L_1 - \varepsilon \quad \forall\, k\geq N,
$$
namely only a finite number of elements is smaller than $L_1 - \varepsilon$.
\item[(2)] For every $\varepsilon>0$ there exist infinitely many $k\in \N$ such that 
$$
\alpha_k < L_1+\varepsilon.
$$
\end{itemize}
Similarly
\begin{itemize}
\item[(3)] For every $\varepsilon>0$ there exists $N\in \N$ such that 
$$
\alpha_k  < L_2+\varepsilon \quad \forall\, k\geq N,
$$
namely only a finite number of elements is larger than $L_2 + \varepsilon$.
\item[(4)] For every $\varepsilon>0$ there exist infinitely many $k\in \N$ such that 
$$
\alpha_k > L_2-\varepsilon.
$$
\end{itemize}
\end{proposition}
\bigskip
\begin{remark}It can be shown using the last proposition that 
	\begin{align*}
	\limsup_{k\to \infty} \alpha_k&=\mathrm{max}\left\{\lim_{n\to \infty} \alpha_{k_n}: (\alpha_{k_n})_n \,\, \text{is a convergent subsequence} \right\}
	\end{align*}
	so that $\limsup_{k\to \infty} \alpha_k$ is the largest of the subsequential limits of $(\alpha_k)$.
	To see this, let $(\alpha_{k_n})_{n\in\N}$ be a convergent subsequence of $(\alpha_k)_{k\in \N}$ with limit $l$ as $n\rightarrow\infty$.
	Then by Proposition \ref{p:limsup} , for any $\epsilon >0$, there exists $N\in\N$ such that 
	$$
	L_1 -\epsilon  < \alpha_{k_n} < L_2+\epsilon \ \ \forall n\geq N.
	$$
	Passing to the limit $n\rightarrow \infty$ we obtain $L_1-\epsilon \leq l \leq L_2+\epsilon$ and by the arbitrariness of $\epsilon >0$ it follows that $L_1\leq l\leq L_2$.
	 Finally, we can use Proposition \ref{p:limsup} to construct a subsequence converging to $L_2$, it follows then that $L_2$ is itself the limit of a subsequence and hence  $\limsup_{k\rightarrow\infty}(\alpha_k)$ is  the \textbf{largest} subsequential limit of $(\alpha_k)_k$. Similarly,  
	\begin{align*}
	\liminf_{k\to \infty} \alpha_k&= \mathrm{min}\left\{\lim_{n\to \infty} \alpha_{k_n}: (\alpha_{k_n})_n \,\, \text{is a convergent subsequence} \right\}
	\end{align*}
	so that $\liminf_{k\to \infty} \alpha_k$ is the \textbf{smallest} of the subsequential limits of $(\alpha_k)$. 
\end{remark}
\newpage


\end{proposition}


\bigskip


We recall some main results relating to convergence of series in $\R$.
\bigskip
\begin{definition}[Convergence of a series]
	Let $(\alpha_k)$ be a sequence of real numbers, then the series 
	$$
	\sum_{k=1}^\infty \alpha_k
	$$
	is said to \textbf{converge} to the sum $s\in\R$ if and only if  the sequence of partial sums $(s_n)_{n\in \N}$ defined by 
	$$
	s_n=\sum_{k=1}^{n} \alpha _k \ \ \forall n\in\N
	$$ 
	converges to $s$ as $n\rightarrow\infty$.
	
	
	\noindent The series  $\sum_{k=1}^\infty \alpha_k$ is said to be \textbf{absolutely convergent} if $\sum_{k=1}^\infty |\alpha_k|$ is a convergent series. A series which is convergent but not absolutely convergent is said to be \textbf{conditionally convergent}.
\end{definition}

\bigskip
\begin{remark}
Using Proposition \ref{cauchycritseq} on the sequence of partial sums $(s_n)_{n\in\N}$ it follows that	if the series $\sum_{k=1}^{\infty}\alpha _k$ is absolutely convergent, then it is convergent. 
\end{remark}

\bigskip
\begin{theorem}[Vanishing test]
	Let $(\alpha_k)$ be a sequence of real numbers. If the series 
	$$
	\sum_{k=1}^\infty \alpha_k
	$$
	converges (to a finite limit), then 
	$$
	\lim_{k\to \infty} \alpha_k =0.
	$$
\end{theorem}

\bigskip

\begin{theorem}[Comparison test]
	Suppose that $\sum_{k=1}^{\infty}\alpha _k$ and $\sum_{k=1}^{\infty}\beta _k$ are two series satisfying
	$$
	0\leq \alpha_k\leq \beta _k \, \, \forall k\in\N.
	$$
	If $\sum_{k=1}^{\infty}\beta _k$ converges, then $\sum_{k=1}^{\infty}\alpha _k$ converges.
\end{theorem}

\bigskip



\begin{theorem}[Ratio test]
Let $(\alpha_k)$ be a sequence of real numbers such that $\alpha_k$ is nonzero for $k$ sufficiently large and let
$$
L_1 = \liminf_{k\to \infty}\left| \frac{\alpha_{k+1}}{\alpha_k}\right|, \quad \text{and } \quad L_2 = \limsup_{k\to \infty}\left| \frac{\alpha_{k+1}}{\alpha_k}\right|.
$$
Then the series 
$$
\sum_{k=1}^\infty \alpha_k
$$
converges absolutely (to a finite limit) if $0\leq L_2<1$ and diverges or does not converge if $1< L_1\leq +\infty$.
\end{theorem}


\bigskip


\begin{theorem}[Root test]
Let $(\alpha_k)$ be a sequence of real numbers, and let
$$
\gamma = \limsup_{k\to \infty}\left|\alpha_k\right|^{\frac1k}.
$$
Then the series 
$$
\sum_{k=1}^\infty \alpha_k
$$
converges absolutely (to a finite limit) if $0\leq \gamma<1$ and diverges or does not converge if $1<\gamma\leq +\infty$.
\end{theorem}






\subsection{Continuity and integrability}

\begin{definition} Let $A\subset \R$ be a set and $f : A \to \R$ a function. Suppose that $x \in A$. We say that $f$ is continuous at $x$ if
$$
\forall\, \varepsilon \,\, \exists\, \delta>0 \quad \textrm{such that } \, \forall \, y\in A:  |y - x| < \delta \Rightarrow |f (y) - f (x)| < \varepsilon.
$$
Equivalently, in terms of sequences, we have that $f$ is continuous at $x$ if for any sequence $(x_k)_{k\in \N}$ in $A$ with $x=\lim_{k\to \infty} x_k$, we have  
$$
f(x)=\lim_{k\to \infty} f(x_k).
$$
We say that $f$ is continuous if it is continuous at every point of $A$. 

We say that $f$ is uniformly continuous if
$$
\forall\, \varepsilon \,\, \exists\, \delta>0 \quad \textrm{such that } \, \forall \, x, y\in A:  |y - x| < \delta \Rightarrow |f (y) - f (x)| < \varepsilon.
$$
Finally, we say that $f$ is Lipschitz continuous if there exists a number $L > 0$ such that for all $x,y \in A$,
$$
|f(y) - f(x)| \le L |y - x|.
$$
\end{definition}

These definitions may have been given in MA10207 only for functions defined on an interval. The conditions are exactly the same, however, for any set $A\subset \R$. If $A$ is a closed, bounded interval, then continuity has particularly nice consequences.

\begin{theorem}[Theorem of uniform continuity] 
Let $I \subset \R$ be a closed, bounded interval and suppose that $f : I \to \R$ is continuous. Then $f$ is uniformly continuous.
\end{theorem}

\begin{theorem}[Weierstrass extreme value theorem]
Let $I \subset \R$ be a closed, bounded interval and suppose that $f : I \to \R$ is continuous. Then $f$ is bounded and attains its infimum and supremum.
\end{theorem}

\medskip
For Riemann integration, the notation we will use (it might differ slightly from what you have seen last year) is the following.
\bigskip
\begin{definition}
A function $f:[a,b]\ \to \R$ is said to be Riemann integrable on $[a,b]$ if for every $\varepsilon>0$ there exists a subdivision (partition) $\Delta$ of $[a,b]$, 
$\Delta = \{a=x_0<x_1<\dots<x_M=b\}$ such that 
\begin{equation}\label{UL}
U(f,\Delta) - L(f,\Delta) = \sum_{n=1}^M \left(\sup_{I_n} f - \inf_{I_n} f \right) |I_n| <\varepsilon, \quad I_n = x_{n+1}-x_n,
\end{equation}
where $U(f,\Delta), L(f,\Delta)$ denote the  corresponding upper and lower sums respectively. 

We also denote by $\omega(f,I_n):= \sup_{I_n} f - \inf_{I_n} f$ the oscillation of $f$ on $I_n$; in this case \eqref{UL} can be rewritten as 
$$
U(f,\Delta) - L(f,\Delta) = \sum_{n=1}^M \omega(f,I_n)\, |I_n| <\varepsilon.
$$

\end{definition}
